# Introduction

Answer Server uses Knowledge Discovery technology to provide specific and concise answers to a user's questions.

After completing this tutorial, you will have a working end-to-end question answering system based on your indexed documents. The system includes curated answer (FAQ) management, as well as integration with LLMs for a fully on-premise/off-cloud generative AI-powered interaction with your data.

## PART I - Configure and run the `data-admin` deployment

Explore and deploy an end-to-end question-answering Knowledge Discovery system.

Start [here](./PART_I.md).

## PART II - Answer questions with RAG

Set up **RAG** (Retrieval Augmented Generation), which uses a large language model (LLM) to generate answers by querying your Knowledge Discovery Content for relevant trusted documents.

Start [here](./PART_II.md).

## PART III - Combine with NiFi ingest

Extend this containerized deployment to add NiFi and index more data to interrogate with Knowledge Discovery Answer Server.

Start [here](./PART_III.md).

## PART IV - Conversations

Set up conversations with Knowledge Discovery Answer Server to enable a chat-style interaction.

Start [here](./PART_IV.md).

## PART V - Answer questions with Answer Bank

Use Knowledge Discovery Data Admin to create and administer a trusted store of reference questions and answers.

<!-- Start [here](./PART_V.md). -->

> COMING SOON!

## Next steps

Explore some advanced Knowledge Discovery configurations, in the [showcase section](../../README.md#showcase-lessons).
