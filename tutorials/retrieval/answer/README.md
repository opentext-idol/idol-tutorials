# Introduction

Answer Server uses Knowledge Discovery technology to provide specific and concise answers to a user's questions.

After completing this tutorial, you will have a working end-to-end question answering system based on your indexed documents. The system includes curated answer (FAQ) management, as well as integration with LLMs for a fully on-premise/off-cloud generative AI-powered interaction with your data.

## PART I - Configure and run the `data-admin` deployment

Explore and deploy an end-to-end question-answering Knowledge Discovery system.

Start [Part I](./PART_I.md).

## PART II - Answer questions with RAG

Set up **RAG** (Retrieval Augmented Generation), which uses a Large Language Model (LLM) to generate answers by querying your Knowledge Discovery Content for relevant trusted documents.

Start [Part II](./PART_II.md).

## PART III - Combine with NiFi ingest

Extend this containerized deployment to add NiFi and index more data to interrogate with Knowledge Discovery Answer Server.

Start [Part III](./PART_III.md).

## PART IV - Conversations

Set up conversations with Knowledge Discovery Answer Server to enable a chat-style interaction. With follow-up questions that preserve context, users can obtain more specific answers.

Start [Part IV](./PART_IV.md).

## PART V - Answer questions with Answer Bank

Use Knowledge Discovery Data Admin to create and administer a trusted store of curated answers, an intelligent FAQ.

> COMING SOON!

## Next steps

Explore some advanced Knowledge Discovery configurations, in the [showcase section](../../README.md#showcase-lessons).
